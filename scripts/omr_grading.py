import json
import sys
import cv2
import numpy as np
import os

# --- ìƒìˆ˜ ë° ì„¤ì • ---
TARGET_WIDTH = 2480
TARGET_HEIGHT = 3508



# --- í•¨ìˆ˜ ì •ì˜ ---

def load_image(image_path):
    """ì´ë¯¸ì§€ ë¡œë“œ ë° í¬ê¸° ë°˜í™˜ (JPEG ê²½ê³  ì–µì œ)"""
    # stderrë¥¼ /dev/nullë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸í•˜ì—¬ JPEG ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ê³  ì–µì œ
    stderr_fd = sys.stderr.fileno()
    old_stderr = os.dup(stderr_fd)
    devnull = os.open(os.devnull, os.O_WRONLY)
    
    try:
        os.dup2(devnull, stderr_fd)
        img = cv2.imread(image_path)
    finally:
        os.dup2(old_stderr, stderr_fd)
        os.close(old_stderr)
        os.close(devnull)
    
    if img is None:
        raise FileNotFoundError(f"Image not found at: {image_path}")
    return img, img.shape[:2]

def resize_image_to_target(img, target_width=TARGET_WIDTH, target_height=TARGET_HEIGHT):
    """ì´ë¯¸ì§€ë¥¼ íƒ€ê²Ÿ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì§• (ë¹„ìœ¨ ìœ ì§€)"""
    h, w = img.shape[:2]

    # í˜„ì¬ ì´ë¯¸ì§€ê°€ ì´ë¯¸ íƒ€ê²Ÿ í¬ê¸°ì¸ ê²½ìš°
    if w == target_width and h == target_height:
        return img, 1.0, 1.0

    # ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚°
    scale_x = target_width / w
    scale_y = target_height / h

    # ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì§•
    new_width = int(w * scale_x)
    new_height = int(h * scale_y)

    # INTER_CUBICì„ ì‚¬ìš©í•˜ì—¬ ë” ë‚˜ì€ í’ˆì§ˆë¡œ ë¦¬ì‚¬ì´ì§•
    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)

    return resized_img, scale_x, scale_y

def gamma_correction(img, gamma=0.7):
    """ê°ë§ˆ ë³´ì •ìœ¼ë¡œ ë°ê¸° ê³¡ì„  ì¡°ì •"""
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(img, table)

def unsharp_mask(img, kernel_size=(5, 5), sigma=1.0, amount=1.0):
    """ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ê²½ê³„ ì„ ëª…í™”"""
    if len(img.shape) == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    blurred = cv2.GaussianBlur(img, kernel_size, sigma)
    sharpened = cv2.addWeighted(img, 1.0 + amount, blurred, -amount, 0)
    return sharpened

def deskew_image_with_barcodes(img):
    """ë°”ì½”ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ ê¸°ìš¸ê¸° ë³´ì •
    
    find_top_black_rectanglesì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ë°”ì½”ë“œë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
    (í•¨ìˆ˜ ì •ì˜ ìˆœì„œ ë¬¸ì œë¡œ ë‚´ë¶€ì— êµ¬í˜„)
    """
    try:
        # ìƒë‹¨ ë°”ì½”ë“œ ì°¾ê¸° (find_top_black_rectanglesì™€ ë™ì¼í•œ ë¡œì§)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)
        
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        img_height, img_width = img.shape[:2]
        top_area_threshold = img_height * 0.15
        
        top_rectangles = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            if (y < top_area_threshold and
                w > 10 and h > 10 and
                w < 300 and h < 300):
                center_x = x + w // 2
                center_y = y + h // 2
                top_rectangles.append({'center': (center_x, center_y)})
        
        if len(top_rectangles) < 15:
            return img
        
        # Yì¶• ì •ë ¬ â†’ ìƒìœ„ 23ê°œ ì„ íƒ â†’ Xì¶• ì •ë ¬
        top_rectangles.sort(key=lambda x: x['center'][1])
        top_rectangles = top_rectangles[:23]
        top_rectangles.sort(key=lambda x: x['center'][0])
        
        if len(top_rectangles) >= 10:
            # ì–‘ ëì˜ ë°”ì½”ë“œë“¤ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ìš¸ê¸° ê³„ì‚°
            left_points = top_rectangles[:5]
            right_points = top_rectangles[-5:]
            
            left_avg_x = np.mean([p['center'][0] for p in left_points])
            left_avg_y = np.mean([p['center'][1] for p in left_points])
            right_avg_x = np.mean([p['center'][0] for p in right_points])
            right_avg_y = np.mean([p['center'][1] for p in right_points])
            
            delta_y = right_avg_y - left_avg_y
            delta_x = right_avg_x - left_avg_x
            
            if delta_x == 0:
                return img
            
            angle_rad = np.arctan2(delta_y, delta_x)
            angle_deg = np.degrees(angle_rad)
            
            # ê¸°ìš¸ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë³´ì • ë¶ˆí•„ìš” (0.3ë„ ë¯¸ë§Œ)
            if abs(angle_deg) < 0.3:
                return img
            
            # ê¸°ìš¸ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ë³´ì •í•˜ì§€ ì•ŠìŒ (10ë„ ì´ˆê³¼)
            if abs(angle_deg) > 10:
                return img
            
            # ì´ë¯¸ì§€ ì¤‘ì‹¬ì  ê¸°ì¤€ìœ¼ë¡œ íšŒì „
            center = (img_width // 2, img_height // 2)
            rotation_matrix = cv2.getRotationMatrix2D(center, angle_deg, 1.0)
            
            deskewed = cv2.warpAffine(
                img, rotation_matrix, (img_width, img_height),
                flags=cv2.INTER_CUBIC,
                borderMode=cv2.BORDER_REPLICATE
            )
            
            return deskewed
        
        return img
        
    except Exception:
        # ë³´ì • ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
        return img

def preprocess_omr_image(img):
    """OMR ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê°•í™”"""
    # 1. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.GaussianBlur(img, (3, 3), 0)

    # 2. ê°ë§ˆ ë³´ì •ìœ¼ë¡œ ë°ê¸° ì¡°ì ˆ (ì–´ë‘ìš´ ë§ˆí‚¹ì„ ë” ì§„í•˜ê²Œ)
    gamma_corrected = gamma_correction(denoised, gamma=0.7)

    # 3. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    if len(gamma_corrected.shape) == 3:
        gray = cv2.cvtColor(gamma_corrected, cv2.COLOR_BGR2GRAY)
    else:
        gray = gamma_corrected

    # 4. CLAHEë¡œ ì§€ì—­ì  ëŒ€ë¹„ í–¥ìƒ
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)

    # 5. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ê²½ê³„ ì„ ëª…í™”
    sharpened = unsharp_mask(enhanced, amount=0.8)

    # 6. BGRë¡œ ë‹¤ì‹œ ë³€í™˜ (ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´)
    result = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2BGR)

    return result


def calculate_marking_density(img, x, y, width=30, height=60):
    """íŠ¹ì • ì¢Œí‘œ ì£¼ë³€ ì˜ì—­ì˜ ë§ˆí‚¹ ë°€ë„ ê³„ì‚°"""
    # ì˜ì—­ ê²½ê³„ í™•ì¸
    h, w = img.shape[:2]
    x1 = max(0, x - width//2)
    y1 = max(0, y - height//2)
    x2 = min(w, x + width//2)
    y2 = min(h, y + height//2)

    # í•´ë‹¹ ì˜ì—­ ì¶”ì¶œ
    region = img[y1:y2, x1:x2]
    if region.size == 0:
        return 0.0

    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ (í•„ìš”ì‹œ)
    if len(region.shape) == 3:
        region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)

    # í‰ê·  ì–´ë‘  ì •ë„ (0~255 ë²”ìœ„ì—ì„œ ë‚®ì„ìˆ˜ë¡ ì–´ë‘¡ë‹¤)
    avg_darkness = 255 - np.mean(region)

    # ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨ (ì„ê³„ê°’ì„ ì¡°ì •: 180 ì´í•˜)
    dark_pixels = np.sum(region < 180)  # 200ì—ì„œ 180ìœ¼ë¡œ ë‹¤ì‹œ ì¡°ì • (ë” ì—„ê²©í•˜ê²Œ)
    total_pixels = region.size
    dark_ratio = dark_pixels / total_pixels

    # ì¤‘ê°„ ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨ (ì‹¤ì œ ë§ˆí‚¹ ë²”ìœ„)
    medium_dark_pixels = np.sum(region < 160)  # 160 ì´í•˜ë§Œ (ì‹¤ì œ ë§ˆí‚¹)
    medium_dark_ratio = medium_dark_pixels / total_pixels

    # ë§¤ìš° ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨ (í™•ì‹¤í•œ ë§ˆí‚¹)
    very_dark_pixels = np.sum(region < 120)
    very_dark_ratio = very_dark_pixels / total_pixels

    # ë°€ë„ ì ìˆ˜: ë§¤ìš° ì–´ë‘ìš´ í”½ì…€ì„ ë” ì¤‘ìš”í•˜ê²Œ (ì‹¤ì œ ë§ˆí‚¹ ìš°ì„ )
    density_score = (avg_darkness / 255.0) * 0.2 + dark_ratio * 0.2 + medium_dark_ratio * 0.4 + very_dark_ratio * 0.2

    return density_score



upperValueSquare = 180
def find_top_black_rectangles(img):
    """ìƒë‹¨ ê²€ì€ìƒ‰ ì‚¬ê°í˜•ë“¤ì„ ì°¾ì•„ì„œ ì¢Œí‘œ ë°˜í™˜"""
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ê²€ì€ìƒ‰ ì˜ì—­ ì°¾ê¸° (ì„ê³„ê°’ ì¡°ì •)
    _, thresh = cv2.threshold(gray, upperValueSquare, 255, cv2.THRESH_BINARY_INV)

    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì‚¬ê°í˜• ë‚´ë¶€ êµ¬ë© ë©”ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±°
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    # MORPH_CLOSE: êµ¬ë©ì„ ë©”ìš°ê³  ë¶„í• ëœ ì˜ì—­ì„ ì—°ê²°
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    # MORPH_OPEN: ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    # ì»¨íˆ¬ì–´ ì°¾ê¸°
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # ìƒë‹¨ ì˜ì—­ì˜ ì‚¬ê°í˜•ë“¤ë§Œ í•„í„°ë§ (ì´ë¯¸ì§€ ìƒë‹¨ 5% ì˜ì—­)
    top_rectangles = []
    img_height = img.shape[0]
    top_area_threshold = img_height * 0.15



    for contour in contours:
        # ì»¨íˆ¬ì–´ì˜ ê²½ê³„ ì‚¬ê°í˜•
        x, y, w, h = cv2.boundingRect(contour)

        # ìƒë‹¨ ì˜ì—­ì— ìˆê³ , ì ì ˆí•œ í¬ê¸°ì¸ ì‚¬ê°í˜•ë§Œ ì„ íƒ
        if (y < top_area_threshold and
            w > 10 and h > 10 and  # ë„ˆë¬´ ì‘ì€ ì‚¬ê°í˜• ì œì™¸ (20ì—ì„œ 10ìœ¼ë¡œ ì™„í™”)
            w < 300 and h < 300):  # ë„ˆë¬´ í° ì‚¬ê°í˜• ì œì™¸ (200ì—ì„œ 300ìœ¼ë¡œ ì™„í™”)

            # ì‚¬ê°í˜•ì˜ ì¤‘ì‹¬ì ê³¼ í¬ê¸° ì €ì¥
            center_x = x + w // 2
            center_y = y + h // 2
            top_rectangles.append({
                'center': (center_x, center_y),
                'bbox': (x, y, w, h),
                'area': w * h
            })
        else:
            pass

    # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ Yì¶• ì •ë ¬ í›„ ì„ íƒ
    # Yì¶• ì •ë ¬ â†’ ê°€ì¥ ìœ„ìª½ 23ê°œ ì„ íƒ (ìƒë‹¨ ë°”ì½”ë“œë“¤)
    top_rectangles.sort(key=lambda x: x['center'][1])  # Yì¶• ì˜¤ë¦„ì°¨ìˆœ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
    selected_rectangles = top_rectangles[:23]  # ê°€ì¥ ìœ„ìª½ 23ê°œ
    selected_rectangles.sort(key=lambda x: x['center'][0])  # ìµœì¢… Xì¶• ì •ë ¬ (ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ)



    return selected_rectangles

def find_side_black_rectangles(img):
    """ì¢Œìš°ì¸¡ ê²€ì€ìƒ‰ ì‚¬ê°í˜•ë“¤ì„ ì°¾ì•„ì„œ ì¢Œí‘œ ë°˜í™˜ (Yì¶• ê³„ì‚°ìš©)"""
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # ê²€ì€ìƒ‰ ì˜ì—­ ì°¾ê¸° (ì„ê³„ê°’ ì¡°ì •)
    _, thresh = cv2.threshold(gray, upperValueSquare, 255, cv2.THRESH_BINARY_INV)

    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì‚¬ê°í˜• ë‚´ë¶€ êµ¬ë© ë©”ìš°ê¸° ë° ë…¸ì´ì¦ˆ ì œê±°
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    # MORPH_CLOSE: êµ¬ë©ì„ ë©”ìš°ê³  ë¶„í• ëœ ì˜ì—­ì„ ì—°ê²°
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    # MORPH_OPEN: ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    # ì»¨íˆ¬ì–´ ì°¾ê¸°
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    img_height, img_width = img.shape[:2]

    # ì¢Œì¸¡ê³¼ ìš°ì¸¡ ì˜ì—­ ì •ì˜
    left_area_threshold = img_width * 0.15  # ì¢Œì¸¡ 5% ì˜ì—­ (ì „í™”ë²ˆí˜¸ìš©)
    right_area_start = img_width * 0.85     # ìš°ì¸¡ 5% ì˜ì—­ ì‹œì‘ì  (ë‹µì•ˆìš©)

    left_rectangles = []
    right_rectangles = []

    for contour in contours:
        x, y, w, h = cv2.boundingRect(contour)
        center_x = x + w // 2
        center_y = y + h // 2

        # ì ì ˆí•œ í¬ê¸°ì¸ ì‚¬ê°í˜•ë§Œ ì„ íƒ
        if (w > 20 and h > 20 and
            w < 70 and h < 70):

            # ì¢Œì¸¡ ì˜ì—­ì˜ ì‚¬ê°í˜•ë“¤ (ì „í™”ë²ˆí˜¸ìš©)
            if center_x < left_area_threshold:
                left_rectangles.append({
                    'center': (center_x, center_y),
                    'bbox': (x, y, w, h),
                    'area': w * h
                })

            # ìš°ì¸¡ ì˜ì—­ì˜ ì‚¬ê°í˜•ë“¤ (ì„ ì§€ìš©)
            elif center_x > right_area_start:
                right_rectangles.append({
                    'center': (center_x, center_y),
                    'bbox': (x, y, w, h),
                    'area': w * h
                })

    # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ Xì¶• ì •ë ¬ í›„ ì„ íƒ
    # ì¢Œì¸¡: Xì¶• ì •ë ¬ â†’ ì•ìª½ 10ê°œ ì„ íƒ (ê°€ì¥ ì™¼ìª½ ë°”ì½”ë“œë“¤)
    left_rectangles.sort(key=lambda x: x['center'][0])  # Xì¶• ì˜¤ë¦„ì°¨ìˆœ
    left_selected = left_rectangles[:10]  # ê°€ì¥ ì™¼ìª½ 10ê°œ
    left_selected.sort(key=lambda x: x['center'][1])  # ìµœì¢… Yì¶• ì •ë ¬

    # ìš°ì¸¡: Xì¶• ì •ë ¬ â†’ ë’¤ìª½ 20ê°œ ì„ íƒ (ê°€ì¥ ì˜¤ë¥¸ìª½ ë°”ì½”ë“œë“¤)
    right_rectangles.sort(key=lambda x: x['center'][0])  # Xì¶• ì˜¤ë¦„ì°¨ìˆœ
    right_selected = right_rectangles[-20:] if len(right_rectangles) >= 20 else right_rectangles  # ê°€ì¥ ì˜¤ë¥¸ìª½ 20ê°œ
    right_selected.sort(key=lambda x: x['center'][1])  # ìµœì¢… Yì¶• ì •ë ¬



    return left_selected, right_selected

def define_phone_positions(img_width, img_height, top_rectangles, left_rectangles):
    """ì „í™”ë²ˆí˜¸ ì „ìš© ìœ„ì¹˜ ê³„ì‚° (1-8ë²ˆ ì‚¬ê°í˜•, 1-10ë²ˆ ìˆ«ì ìë¦¬)"""
    phone_positions = {}

    # 1-8ë²ˆ ì‚¬ê°í˜•: ì „í™”ë²ˆí˜¸ ìë¦¬ìˆ˜ (Xì¶•)
    for rect_index in range(8):
        if rect_index < len(top_rectangles):
            rect_center_x = top_rectangles[rect_index]['center'][0]
            digit_position = rect_index + 1  # 1-8ë²ˆì§¸ ìë¦¬

            # 0-9ë²ˆ ìˆ«ì (Yì¶•: ì™¼ìª½ ë„¤ëª¨ ì‚¬ìš©)
            if len(left_rectangles) >= 10:
                phone_positions[digit_position] = {}
                for digit in range(10):  # 0-9
                    if digit < len(left_rectangles):
                        y = left_rectangles[digit]['center'][1]
                        phone_positions[digit_position][str(digit)] = (rect_center_x, y)

    return phone_positions

def define_answer_positions(img_width, img_height, top_rectangles, left_rectangles, right_rectangles):
    """ë‹µì•ˆ ì „ìš© ìœ„ì¹˜ ê³„ì‚° (9-23ë²ˆ ì‚¬ê°í˜•, 1-45ë²ˆ ë¬¸ì œ)"""
    positions = {}

    # 9-13ë²ˆ ì‚¬ê°í˜•: 1-20ë²ˆ ë¬¸ì œì˜ 1-5ë²ˆ ì„ ì§€
    for rect_index in range(8, 13):  # 9-13ë²ˆ ì‚¬ê°í˜•
        if rect_index < len(top_rectangles):
            rect_center_x = top_rectangles[rect_index]['center'][0]
            choice_num = rect_index - 7  # 1, 2, 3, 4, 5ë²ˆ ì„ ì§€

            # 1-20ë²ˆ ë¬¸ì œ
            if len(right_rectangles) >= 20:
                for q in range(1, 21):  # 1-20ë²ˆ ë¬¸ì œ
                    if q not in positions:
                        positions[q] = {}

                    question_index = q - 1  # 1ë²ˆ ë¬¸ì œ -> 0ë²ˆ ì¸ë±ìŠ¤
                    if question_index < len(right_rectangles):
                        y = right_rectangles[question_index]['center'][1]
                        positions[q][str(choice_num)] = (rect_center_x, y)

    # 14-18ë²ˆ ì‚¬ê°í˜•: 21-40ë²ˆ ë¬¸ì œì˜ 1-5ë²ˆ ì„ ì§€
    for rect_index in range(13, 18):  # 14-18ë²ˆ ì‚¬ê°í˜•
        if rect_index < len(top_rectangles):
            rect_center_x = top_rectangles[rect_index]['center'][0]
            choice_num = rect_index - 12  # 1, 2, 3, 4, 5ë²ˆ ì„ ì§€

            # 21-40ë²ˆ ë¬¸ì œ
            if len(right_rectangles) >= 20:
                for q in range(21, 41):  # 21-40ë²ˆ ë¬¸ì œ
                    if q not in positions:
                        positions[q] = {}

                    question_index = q - 21  # 21ë²ˆ ë¬¸ì œ -> 0ë²ˆ ì¸ë±ìŠ¤
                    if question_index < len(right_rectangles):
                        y = right_rectangles[question_index]['center'][1]
                        positions[q][str(choice_num)] = (rect_center_x, y)

    # 19-23ë²ˆ ì‚¬ê°í˜•: 41-45ë²ˆ ë¬¸ì œì˜ 1-5ë²ˆ ì„ ì§€
    for rect_index in range(18, 23):  # 19-23ë²ˆ ì‚¬ê°í˜•
        if rect_index < len(top_rectangles):
            rect_center_x = top_rectangles[rect_index]['center'][0]
            choice_num = rect_index - 17  # 1, 2, 3, 4, 5ë²ˆ ì„ ì§€

            # 41-45ë²ˆ ë¬¸ì œ
            if len(right_rectangles) >= 5:
                for q in range(41, 46):  # 41-45ë²ˆ ë¬¸ì œ
                    if q not in positions:
                        positions[q] = {}

                    question_index = q - 41  # 41ë²ˆ ë¬¸ì œ -> 0ë²ˆ ì¸ë±ìŠ¤
                    if question_index < len(right_rectangles):
                        y = right_rectangles[question_index]['center'][1]
                        positions[q][str(choice_num)] = (rect_center_x, y)

    return positions

def estimate_phone_number_with_density(img, phone_positions, min_density=0.17):
    """ë‹¨ì¼ ì„ íƒì´ ë³´ì¥ëœ ê²½ìš° ê°„ë‹¨í•œ ì „í™”ë²ˆí˜¸ ì¶”ì •"""
    phone_selected = {}

    # ê° ìë¦¬ë³„ë¡œ ë°€ë„ê°€ ê°€ì¥ ë†’ì€ ìˆ«ì ì°¾ê¸°
    for digit_pos, digit_choices in phone_positions.items():
        if not digit_choices:
            phone_selected[digit_pos] = "0"
            continue

        # ê° ìˆ«ì(0-9)ì˜ ë°€ë„ ê³„ì‚°
        digit_densities = {}
        for digit, coord in digit_choices.items():
            x, y = coord
            density = calculate_marking_density(img, x, y)
            digit_densities[digit] = density

        # ê°€ì¥ ë†’ì€ ë°€ë„ ì°¾ê¸°
        highest_digit, highest_density = max(digit_densities.items(), key=lambda x: x[1])

        # ì„ê³„ê°’ ì´ìƒì´ë©´ ì„ íƒ, ì•„ë‹ˆë©´ 0 (ë¹ˆì¹¸)
        if highest_density >= min_density:
            phone_selected[digit_pos] = highest_digit
        else:
            phone_selected[digit_pos] = "0"

    return phone_selected

def estimate_selected_answers_with_density(img, answer_positions, min_density=0.2):
    """ë‹¨ì¼ ì„ íƒì´ ë³´ì¥ëœ ê²½ìš° ê°„ë‹¨í•œ ë‹µì•ˆ ì¶”ì •"""
    selected = {}

    # ëª¨ë“  ë‹µì•ˆ ë¬¸ì œ ì²˜ë¦¬ (1-45ë²ˆ)
    for q_num, choices in answer_positions.items():
        if not choices:
            selected[str(q_num)] = "ë¬´íš¨"
            continue

        # ê° ì„ ì§€ì˜ ë°€ë„ ê³„ì‚°
        choice_densities = {}
        for choice, coord in choices.items():
            x, y = coord
            density = calculate_marking_density(img, x, y)
            choice_densities[choice] = density

        # ê°€ì¥ ë†’ì€ ë°€ë„ ì°¾ê¸°
        highest_choice, highest_density = max(choice_densities.items(), key=lambda x: x[1])

        # ì„ê³„ê°’ ì´ìƒì´ë©´ ì„ íƒ, ì•„ë‹ˆë©´ ë¬´íš¨ (ë‹µ ì•ˆ ì”€)
        if highest_density >= min_density:
            selected[str(q_num)] = highest_choice
        else:
            selected[str(q_num)] = "ë¬´íš¨"

    return selected



def extract_phone_number(phone_selected):
    """ì „í™”ë²ˆí˜¸ 8ìë¦¬ ì¶”ì¶œ"""
    phone_digits = []

    # 1ë²ˆë¶€í„° 8ë²ˆê¹Œì§€ ìë¦¬ìˆ˜ì—ì„œ ì „í™”ë²ˆí˜¸ ìˆ˜ì§‘
    for i in range(1, 9):
        if i in phone_selected:
            digit = phone_selected[i]
            # ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸ (0-9 ë²”ìœ„)
            if digit and digit != "ë¬´íš¨":
                try:
                    digit_int = int(digit)
                    if 0 <= digit_int <= 9:
                        phone_digits.append(str(digit_int))
                    else:
                        phone_digits.append("0")  # ì˜ëª»ëœ ê°’ì€ 0ìœ¼ë¡œ ì²˜ë¦¬
                except ValueError:
                    phone_digits.append("0")  # ë³€í™˜ ì‹¤íŒ¨ì‹œ 0ìœ¼ë¡œ ì²˜ë¦¬
            else:
                phone_digits.append("0")  # ë¬´íš¨ì‹œ 0ìœ¼ë¡œ ì²˜ë¦¬
        else:
            phone_digits.append("0")  # ë‹µì•ˆì´ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬

    # 8ìë¦¬ ì „í™”ë²ˆí˜¸ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
    phone_number = "".join(phone_digits)
    return phone_number

def calculate_total_score(selected_answers, correct_answers, question_scores):
    """ì´ì  ê³„ì‚° (ëª¨ë“  ë‹µì•ˆ ë¬¸ì œ 1-45ë²ˆ í¬í•¨)"""
    total = 0
    
    for q_num, correct_answer in correct_answers.items():
        if q_num in selected_answers:
            student_answer = selected_answers[q_num]
            if student_answer == correct_answer:
                score = question_scores.get(q_num, 0)
                total += score
    
    return total

def calculate_grade(total_score):
    """ë“±ê¸‰ ê³„ì‚° (ì´ì  ê¸°ì¤€)"""
    if total_score >= 90:
        return 1
    elif total_score >= 80:
        return 2
    elif total_score >= 70:
        return 3
    elif total_score >= 60:
        return 4
    elif total_score >= 50:
        return 5
    elif total_score >= 40:
        return 6
    elif total_score >= 30:
        return 7
    elif total_score >= 20:
        return 8
    else:
        return 9

def create_results_array(selected_answers, correct_answers, question_scores, question_types):
    """ê²°ê³¼ ë°°ì—´ ìƒì„± (ëª¨ë“  ë‹µì•ˆ ë¬¸ì œ 1-45ë²ˆ í¬í•¨)"""
    results = []
    
    # correct_answersì˜ í‚¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ìƒì„± (ìˆ«ì ì •ë ¬)
    for q_num in sorted(correct_answers.keys(), key=lambda x: int(x)):
        try:
            q_num_int = int(q_num)
            student_answer = selected_answers.get(q_num, "ë¬´íš¨")  # ë¬¸ìì—´ í‚¤ë¡œ ì ‘ê·¼
            correct_answer = correct_answers[q_num]
            score = question_scores.get(q_num, 0)
            question_type = question_types.get(q_num, "ê¸°íƒ€")
            
            earned_score = score if student_answer == correct_answer else 0
            
            results.append({
                "questionNumber": q_num_int,
                "studentAnswer": str(student_answer),
                "correctAnswer": correct_answer,
                "score": score,
                "earnedScore": earned_score,
                "questionType": question_type
            })
        except (ValueError, TypeError):
            continue
    
    return results

def grade_omr(image_path, correct_answers, question_scores, question_types):
    """OMR ì±„ì  ë©”ì¸ í•¨ìˆ˜"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        img, (h, w) = load_image(image_path)

        # ë°”ì½”ë“œ ê¸°ë°˜ ì´ë¯¸ì§€ ê¸°ìš¸ê¸° ë³´ì •
        deskewed_img = deskew_image_with_barcodes(img)

        # ì´ë¯¸ì§€ ë¹„ìœ¨ í™•ì¸ (2480:3508 = 0.7075)
        expected_ratio = TARGET_WIDTH / TARGET_HEIGHT
        actual_ratio = w / h
        ratio_diff = abs(expected_ratio - actual_ratio)
        
        if ratio_diff > 0.01:  # 1% ì´ìƒ ì°¨ì´ë‚˜ë©´ ê²½ê³ 
            pass

        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ë° ìŠ¤ì¼€ì¼ íŒ©í„° ê³„ì‚° (ê¸°ìš¸ê¸° ë³´ì •ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
        resized_img, scale_x, scale_y = resize_image_to_target(deskewed_img)
        resized_h, resized_w = resized_img.shape[:2]

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê°•í™” ì ìš©
        preprocessed_img = preprocess_omr_image(resized_img)






        # ìƒë‹¨ ê²€ì€ìƒ‰ ì‚¬ê°í˜• ì°¾ê¸° (ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©)
        top_rectangles = find_top_black_rectangles(resized_img)


        # ì¢Œìš°ì¸¡ ê²€ì€ìƒ‰ ì‚¬ê°í˜• ì°¾ê¸° (Yì¶• ê³„ì‚°ìš©, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©)
        left_rectangles, right_rectangles = find_side_black_rectangles(resized_img)


        # ì „í™”ë²ˆí˜¸ ìœ„ì¹˜ ê³„ì‚° (1-8ë²ˆ ì‚¬ê°í˜•, 0-9 ìˆ«ì)
        phone_positions = define_phone_positions(resized_w, resized_h, top_rectangles, left_rectangles)

        # ë‹µì•ˆ ìœ„ì¹˜ ê³„ì‚° (9-23ë²ˆ ì‚¬ê°í˜•, 1-45ë²ˆ ë¬¸ì œ)
        answer_positions = define_answer_positions(resized_w, resized_h, top_rectangles, left_rectangles, right_rectangles)











        # ì „í™”ë²ˆí˜¸ ì¶”ì • (ë°€ë„ ê¸°ë°˜, ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
        phone_selected = estimate_phone_number_with_density(preprocessed_img, phone_positions)
        phone_number = extract_phone_number(phone_selected)

        # í•™ìƒ ë‹µì•ˆ ì¶”ì • (1-45ë²ˆ ë¬¸ì œ) - ë°€ë„ ê¸°ë°˜ ë°©ì‹, ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©
        selected_answers = estimate_selected_answers_with_density(preprocessed_img, answer_positions)

        # ë””ë²„ê¹… í•¨ìˆ˜ í˜¸ì¶œ
        debug(
            isActive=False,
            # isActive=True,
            phone_positions=phone_positions,
            answer_positions=answer_positions,
            preprocessed_img=preprocessed_img,
            selected_answers=selected_answers,
            resized_w=resized_w,
            resized_h=resized_h,
            scale_x=scale_x,
            scale_y=scale_y,
            deskewed_img=deskewed_img,
            image_path=image_path
        )

        # ì •ë‹µê³¼ í•™ìƒ ë‹µì•ˆ ë¹„êµ (ëª¨ë“  ë¬¸ì œ)
        correct_count = 0
        for q_num, correct_answer in correct_answers.items():
            if q_num in selected_answers:
                student_answer = selected_answers[q_num]
                if str(student_answer) == str(correct_answer):
                    correct_count += 1

        # ì´ì  ê³„ì‚°
        total_score = calculate_total_score(selected_answers, correct_answers, question_scores)

        # ë“±ê¸‰ ê³„ì‚°
        grade = calculate_grade(total_score)

        # ê²°ê³¼ ë°°ì—´ ìƒì„±
        results = create_results_array(selected_answers, correct_answers, question_scores, question_types)



        final_result = {
            "totalScore": total_score,
            "grade": grade,
            "phoneNumber": phone_number,
            "results": results,
            "imageInfo": {
                "originalSize": f"{w}x{h}",
                "resizedSize": f"{resized_w}x{resized_h}",
                "scaleFactors": {"x": scale_x, "y": scale_y},
                "aspectRatio": {"expected": expected_ratio, "actual": actual_ratio}
            }
        }

        return final_result

    except Exception:
        raise Exception("OMR ì±„ì  ì‹¤íŒ¨") from None

# --- ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---

def debug(isActive=True, **kwargs):
    """ë””ë²„ê¹… ì „ìš© í•¨ìˆ˜ - isActiveê°€ Trueì¼ ë•Œë§Œ ì‘ë™"""
    # ê¸°ìš¸ê¸° ë³´ì •ëœ ì´ë¯¸ì§€ ì €ì¥ (í•­ìƒ ì‹¤í–‰)
    if 'deskewed_img' in kwargs and 'image_path' in kwargs:
        import os
        image_path = kwargs['image_path']
        deskewed_img = kwargs['deskewed_img']
        
        # ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ
        filename = os.path.basename(image_path)
        name, ext = os.path.splitext(filename)
        
        # ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # deskewed í´ë” ìƒì„± (ì—†ìœ¼ë©´)
        deskewed_dir = os.path.join(script_dir, "omr_deskewed")
        os.makedirs(deskewed_dir, exist_ok=True)
        
        # ì €ì¥ ê²½ë¡œ
        save_path = os.path.join(deskewed_dir, f"{name}_deskewed{ext}")
        
        # ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(save_path, deskewed_img)

    
    # ë””ë²„ê¹… ëª¨ë“œê°€ êº¼ì ¸ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ
    if not isActive:
        return
    
    # ì „í™”ë²ˆí˜¸ ìœ„ì¹˜ë³„ ê¸°ë³¸ ë°€ë„ê°’ ì¶œë ¥
    if 'phone_positions' in kwargs and 'preprocessed_img' in kwargs:
        print("\n=== ì „í™”ë²ˆí˜¸ ìœ„ì¹˜ë³„ ê¸°ë³¸ ë°€ë„ê°’ ===")
        for digit_pos, digit_choices in kwargs['phone_positions'].items():
            print(f"ì „í™”ë²ˆí˜¸ {digit_pos}ë²ˆì§¸ ìë¦¬:")
            for digit, coord in digit_choices.items():
                density = calculate_marking_density(kwargs['preprocessed_img'], coord[0], coord[1])
                print(f"  ìˆ«ì {digit}: ë°€ë„ {density:.4f} (ì¢Œí‘œ: {coord})")

    # ë‹µì•ˆ ìœ„ì¹˜ë³„ ê¸°ë³¸ ë°€ë„ê°’ ì¶œë ¥
    if 'answer_positions' in kwargs and 'preprocessed_img' in kwargs:
        print("\n=== ë‹µì•ˆ ìœ„ì¹˜ë³„ ê¸°ë³¸ ë°€ë„ê°’ ===")
        max_min_diffs = []
        first_second_diffs = []  # 1-2ìœ„ ë°€ë„ ì°¨ì´ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

        for q_num, choices in kwargs['answer_positions'].items():
            print(f"ë¬¸ì œ {q_num}ë²ˆ:")
            question_densities = []
            for choice, coord in choices.items():
                density = calculate_marking_density(kwargs['preprocessed_img'], coord[0], coord[1])
                print(f"  ì„ ì§€ {choice}: ë°€ë„ {density:.4f} (ì¢Œí‘œ: {coord})")
                question_densities.append(density)

            # ê° ë¬¸ì œë³„ ìµœëŒ€-ìµœì†Œ ë°€ë„ ì°¨ì´ ê³„ì‚°
            if question_densities:
                # ë°€ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                sorted_densities = sorted(question_densities, reverse=True)
                max_density = sorted_densities[0]  # 1ìœ„
                min_density = sorted_densities[-1]  # 5ìœ„
                diff = max_density - min_density
                max_min_diffs.append(diff)

                # ë°€ë„ ìˆœìœ„ë³„ë¡œ ì¶œë ¥
                print("â†’ ë°€ë„ ìˆœìœ„:")
                for i, density in enumerate(sorted_densities, 1):
                    print(f"    {i}ìœ„: {density:.4f}")

                # 1ìœ„ì™€ 2ìœ„ì˜ ì°¨ì´ ê³„ì‚°
                if len(sorted_densities) >= 2:
                    first_second_diff = sorted_densities[0] - sorted_densities[1]
                    first_second_diffs.append((int(q_num), first_second_diff))  # (ë¬¸ì œë²ˆí˜¸, ì°¨ì´ê°’) íŠœí”Œë¡œ ì €ì¥
                    print(f"  â†’ 1ìœ„-2ìœ„ ë°€ë„ ì°¨ì´: {first_second_diff:.4f} (1ìœ„: {sorted_densities[0]:.4f}, 2ìœ„: {sorted_densities[1]:.4f})")

                print(f"  â†’ ì „ì²´ ë°€ë„ ë²”ìœ„: {diff:.4f} (ìµœëŒ€: {max_density:.4f}, ìµœì†Œ: {min_density:.4f})")
                print()  # ë¬¸ì œ ê°„ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„

        # 1-2ìœ„ ë°€ë„ ì°¨ì´ë¥¼ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í•œ ë²ˆì— ì¶œë ¥
        if first_second_diffs:
            print("\n" + "="*60)
            print("ğŸ“Š ëª¨ë“  ë¬¸ì œ 1-2ìœ„ ë°€ë„ ì°¨ì´ (ì˜¤ë¦„ì°¨ìˆœ)")
            print("="*60)

            # ì°¨ì´ê°’ë§Œ ì¶”ì¶œí•˜ì—¬ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            diff_values = sorted([diff for _, diff in first_second_diffs])

            # ë°°ì—´ í˜•íƒœë¡œ ì¶œë ¥
            print("[" + ", ".join([f"{diff:.4f}" for diff in diff_values]) + "]")

            # íŒŒì¼ì— ì €ì¥
            try:
                import os
                # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ
                script_dir = os.path.dirname(os.path.abspath(__file__))
                file_path = os.path.join(script_dir, "res.txt")

                # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¶”ê°€ ëª¨ë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                mode = 'a' if os.path.exists(file_path) else 'w'
                with open(file_path, mode, encoding='utf-8') as f:
                    # êµ¬ë¶„ì„ ê³¼ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                    if mode == 'a':
                        pass

                    # ë°€ë„ ì°¨ì´ì™€ ì±„ì  ê²°ê³¼ë¥¼ í•¨ê»˜ ì €ì¥
                    result_with_answers = []
                    for q_num, diff in first_second_diffs:
                        # selected_answersëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ: {"1": "1", "2": "ë¬´íš¨", ...}
                        answer = kwargs.get('selected_answers', {}).get(str(q_num), "ë¬´íš¨")
                        result_with_answers.append(f"{diff:.4f}[{answer}]")

                    # ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì €ì¥
                    sorted_results = sorted(result_with_answers, key=lambda x: float(x.split('[')[0]))
                    f.write(", ".join(sorted_results))
                    f.write("\n")

                print(f"ğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {file_path}")
            except Exception as e:
                print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

            # í†µê³„ ì •ë³´ ì¶”ê°€
            all_diffs = [diff for _, diff in first_second_diffs]
            avg_diff = sum(all_diffs) / len(all_diffs)
            min_diff = min(all_diffs)
            max_diff = max(all_diffs)

            print(f"ğŸ“ˆ í†µê³„: í‰ê·  {avg_diff:.4f}, ìµœì†Œ {min_diff:.4f}, ìµœëŒ€ {max_diff:.4f}")
            print("="*60)

    # ì¸ì‹ëœ ë‹µì•ˆ ìš”ì•½ ì¶œë ¥
    if 'selected_answers' in kwargs:
        print("\n=== ì¸ì‹ëœ ë‹µì•ˆ ìš”ì•½ ===")
        recognized_count = 0
        for q_num, answer in kwargs['selected_answers'].items():
            if answer != "ë¬´íš¨":
                recognized_count += 1
                print(f"ë¬¸ì œ {q_num}ë²ˆ: ì„ ì§€ {answer} ì¸ì‹ë¨")

        if recognized_count == 0:
            print("ì¸ì‹ëœ ë‹µì•ˆì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ë¬´íš¨)")
        else:
            print(f"\nì´ {recognized_count}ê°œ ë¬¸ì œì—ì„œ ë‹µì•ˆ ì¸ì‹ë¨")


if __name__ == "__main__":
    try:
        # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±
        if len(sys.argv) != 5:
            sys.exit(1)
        
        image_path = sys.argv[1]
        # APIì—ì„œ ì „ë‹¬ë°›ì€ JSON ë¬¸ìì—´ì„ json.loadsë¡œ ì•ˆì „í•˜ê²Œ íŒŒì‹±
        try:
            correct_answers = json.loads(sys.argv[2])
            question_scores = json.loads(sys.argv[3])
            question_types = json.loads(sys.argv[4])
        except json.JSONDecodeError:
            sys.exit(1)
        
        # OMR ì±„ì  ì‹¤í–‰
        result = grade_omr(image_path, correct_answers, question_scores, question_types)
        
        # JSON ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê·¸ ë©”ì‹œì§€ ì—†ì´)
        print(json.dumps(result, ensure_ascii=False))
        
    except Exception:
        sys.exit(1)
